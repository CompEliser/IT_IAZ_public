{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вступ до штучного інтелекту та аналізу даних\n",
    "\n",
    "#### Означення штучного інтелекту\n",
    "Штучний інтелект (АІ) – це галузь комп'ютерних наук, яка займається створенням систем, здатних виконувати завдання, які вимагають людського інтелекту. Це включає в себе вирішення проблем, навчання, розуміння мови, розпізнавання образів та інше.\n",
    "\n",
    "#### Загальний огляд застосування АІ в аналізі даних\n",
    "АІ використовується в аналізі даних для виявлення закономірностей та інсайтів у великих обсягах даних. До прикладів застосування належать:\n",
    "\n",
    "- **Прогнозування та моделювання:** Використання алгоритмів машинного навчання для прогнозування майбутніх тенденцій.\n",
    "- **Кластеризація та сегментація:** Розподіл даних на групи за певними критеріями.\n",
    "- **Розпізнавання образів:** Аналіз зображень та відео для виявлення певних об'єктів або особливостей.\n",
    "\n",
    "#### Основні поняття та термінологія\n",
    "- **Машинне навчання (ML):** Підгалузь АІ, що охоплює алгоритми та методи, які дозволяють комп'ютерам \"навчатися\" з даних.\n",
    "- **Нейронні мережі:** Основний інструмент в глибокому навчанні, імітують роботу людського мозку для обробки даних.\n",
    "- **Перенавчання (Overfitting):** Ситуація, коли модель машинного навчання занадто точно адаптується до навчальних даних, втрачаючи здатність узагальнювати.\n",
    "\n",
    "---\n",
    "\n",
    "### Приклад Коду: Основи Python для Аналізу Даних\n",
    "\n",
    "**Мета:** Демонстрація основних операцій з даними в Python.\n",
    "\n",
    "```python\n",
    "# Імпортування бібліотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Створення простого DataFrame\n",
    "data = {'Name': ['Anna', 'Bob', 'Charles'],\n",
    "        'Age': [28, 35, 40],\n",
    "        'City': ['Kyiv', 'Lviv', 'Odesa']}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Вивід даних\n",
    "print(df)\n",
    "\n",
    "# Базові операції з DataFrame\n",
    "mean_age = df['Age'].mean()\n",
    "print(\"Середній вік: \", mean_age)\n",
    "\n",
    "# Сортування даних за віком\n",
    "sorted_df = df.sort_values(by='Age', ascending=False)\n",
    "print(sorted_df)\n",
    "```\n",
    "\n",
    "Цей код демонструє базове використання бібліотеки Pandas для створення та маніпуляції з даними у форматі DataFrame, що є дуже корисним в ана"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Типи даних та їх обробка\n",
    "\n",
    "#### Структуровані та Неструктуровані Дані\n",
    "1. **Структуровані дані:** Це дані, які мають визначену структуру та формат. Наприклад, таблиці з фіксованими колонками.\n",
    "2. **Неструктуровані дані:** Це дані без визначеної структури, такі як текст, зображення, відео.\n",
    "\n",
    "#### Попередня Обробка Даних\n",
    "1. **Очищення даних:** Видалення або коригування неправильних, відсутніх або нерелевантних даних.\n",
    "2. **Нормалізація даних:** Приведення різних масштабів атрибутів до спільного діапазону.\n",
    "3. **Перетворення даних:** Зміна формату або структури даних для подальшого аналізу.\n",
    "\n",
    "#### Інструменти для Обробки Даних\n",
    "1. **Pandas:** Бібліотека для обробки та аналізу даних, особливо корисна для роботи зі структурованими даними.\n",
    "2. **NumPy:** Бібліотека для наукових обчислень, яка пропонує потужні структури даних та операції з ними.\n",
    "\n",
    "---\n",
    "\n",
    "### Приклад Коду: Обробка Структурованих Даних\n",
    "\n",
    "**Мета:** Показати основні методи обробки структурованих даних за допомогою Pandas.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Завантаження даних\n",
    "data = pd.read_csv('sample_data.csv')  # Припускаємо, що у нас є файл CSV\n",
    "\n",
    "# Очищення даних\n",
    "# Видалення рядків з відсутніми даними\n",
    "cleaned_data = data.dropna()\n",
    "\n",
    "# Нормалізація даних\n",
    "# Нормалізація колонки 'Age' за допомогою Min-Max нормалізації\n",
    "age_max = cleaned_data['Age'].max()\n",
    "age_min = cleaned_data['Age'].min()\n",
    "cleaned_data['Normalized_Age'] = (cleaned_data['Age'] - age_min) / (age_max - age_min)\n",
    "\n",
    "# Перетворення даних\n",
    "# Конвертація категоріальних даних у числові\n",
    "cleaned_data['Gender'] = cleaned_data['Gender'].map({'Female': 0, 'Male': 1})\n",
    "\n",
    "# Вивід оброблених даних\n",
    "print(cleaned_data.head())\n",
    "```\n",
    "\n",
    "Цей код демонструє типові методи попередньої обробки даних: очищення від відсутніх значень, нормалізацію числових даних для приведення їх до єдиного масштабу, та перетворення категоріальних даних у числові для подальшого аналізу. Pandas є відмінним інструментом для таких завдань, дозволяючи ефективно обробляти великі набори даних."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Візуалізація Даних\n",
    "\n",
    "#### Основи візуалізації (Matplotlib, Seaborn)\n",
    "1. **Matplotlib:** Це основна бібліотека для візуалізації даних в Python, яка дозволяє створювати графіки та діаграми.\n",
    "2. **Seaborn:** Бібліотека, заснована на Matplotlib, яка надає більш високорівневий інтерфейс для створення привабливих та інформативних статистичних графіків.\n",
    "\n",
    "#### Інтерпретація Візуальних Даних\n",
    "Інтерпретація візуальних даних включає аналіз графіків і діаграм для виявлення тенденцій, закономірностей та аномалій у даних.\n",
    "\n",
    "#### Практичні Приклади Візуалізації\n",
    "\n",
    "1. **Створення базового графіка:**\n",
    "   - Використання Matplotlib для створення простого лінійного графіка.\n",
    "2. **Використання Seaborn для створення складніших графіків:**\n",
    "   - Створення графіка розподілу (наприклад, гістограми або ящика з вусами).\n",
    "\n",
    "---\n",
    "\n",
    "### Приклад Коду: Візуалізація Даних з Matplotlib та Seaborn\n",
    "\n",
    "**Мета:** Показати як створювати базові візуалізації з використанням Matplotlib та Seaborn.\n",
    "\n",
    "```python\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "# Завантаження даних\n",
    "data = pd.read_csv('sample_data.csv')  # Припускаємо, що у нас є файл CSV\n",
    "\n",
    "# Базова візуалізація з Matplotlib\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(data['Date'], data['Value'])\n",
    "plt.title('Динаміка значень за датами')\n",
    "plt.xlabel('Дата')\n",
    "plt.ylabel('Значення')\n",
    "plt.show()\n",
    "\n",
    "# Розширена візуалізація з Seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(data['Value'], kde=True)\n",
    "plt.title('Розподіл значень')\n",
    "plt.xlabel('Значення')\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "У цьому прикладі, перший блок коду використовує Matplotlib для створення простого лінійного графіка, який відображає зміну якогось показника в часі. Другий блок коду використовує Seaborn для створення гістограми розподілу значень, з можливістю відображення щільності розподілу (KDE - Kernel Density Estimate). Ці візуалізації допомагають у більш глибокому аналізі та інтерпретації даних."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Частина 2: Використання технологій машинного навчання для аналізу даних"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Основи машинного навчання\n",
    "\n",
    "#### Класифікація алгоритмів машинного навчання\n",
    "1. **Навчання з учителем (Supervised Learning):** Моделі вчаться на попередньо розмічених даних, намагаючись передбачити вихідні значення або класифікувати дані. Приклади включають лінійну регресію, логістичну регресію, нейронні мережі, дерева рішень тощо.\n",
    "2. **Навчання без учителя (Unsupervised Learning):** Моделі вчаться на нерозмічених даних, намагаючись виявити приховані структури. Приклади методів включають кластеризацію (наприклад, K-means) та зниження розмірності (наприклад, PCA).\n",
    "3. **Зміцнювальне навчання (Reinforcement Learning):** Моделі вчаться за допомогою випробувань та помилок, взаємодіючи з середовищем, щоб максимізувати певну винагороду.\n",
    "\n",
    "#### Процес побудови моделі машинного навчання\n",
    "1. **Збір та підготовка даних:** Збір відповідних даних, їх очищення та підготовка до аналізу.\n",
    "2. **Вибір моделі:** Вибір відповідного алгоритму машинного навчання залежно від задачі.\n",
    "3. **Навчання моделі:** Використання навчальних даних для тренування моделі.\n",
    "4. **Тестування та оцінка моделі:** Перевірка ефективності моделі на тестових даних.\n",
    "5. **Тюнінг параметрів:** Налаштування параметрів моделі для покращення її точності.\n",
    "6. **Розгортання моделі:** Використання моделі для реальних завдань або прийняття рішень.\n",
    "\n",
    "---\n",
    "\n",
    "### Приклад Коду: Навчання Моделі Машинного Навчання\n",
    "\n",
    "**Мета:** Демонстрація базового процесу побудови та навчання моделі машинного навчання на прикладі лінійної регресії.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "# Завантаження даних\n",
    "data = pd.read_csv('sample_data.csv')  # Припускаємо, що у нас є файл CSV\n",
    "\n",
    "# Підготовка даних\n",
    "X = data[['feature1', 'feature2']]  # Незалежні змінні\n",
    "y = data['target']  # Залежна змінна\n",
    "\n",
    "# Розподіл даних на навчальні та тестові\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Створення моделі\n",
    "model = LinearRegression()\n",
    "\n",
    "# Навчання моделі\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Оцінка моделі\n",
    "predictions = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "print(f'Середньоквадратична помилка: {mse}')\n",
    "```\n",
    "\n",
    "Цей приклад коду демонструє базовий процес побудови, навчання та тестування моделі лінійної регресії з використанням бібліотеки Scikit-learn. Після підготовки даних, вони діляться на навчальні та тестові набори, після чого модель навчається та тестується, а її ефективність вимірюється за допомогою середньоквадратичної помилки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вибір та Оцінка Моделей\n",
    "\n",
    "#### Критерії Вибору Алгоритмів\n",
    "1. **Тип Задачі:** Вибір алгоритму залежить від типу задачі (класифікація, регресія, кластеризація тощо).\n",
    "2. **Розмір та Якість Даних:** Деякі алгоритми краще працюють з великими наборами даних або вимагають високоякісних даних.\n",
    "3. **Вимоги до Швидкості та Ресурсів:** Необхідно враховувати обмеження на час обчислень та доступні обчислювальні ресурси.\n",
    "4. **Точність та Стійкість Моделі:** Важливо звернути увагу на здатність моделі точно передбачати результати та її стійкість до шуму в даних.\n",
    "\n",
    "#### Крос-валідація та Оцінка Ефективності Моделі\n",
    "1. **Крос-валідація:** Техніка, яка дозволяє оцінити здатність моделі узагальнювати результати на незнайомих даних. Найпоширеніший метод – крос-валідація за k-блоками (k-fold cross-validation).\n",
    "2. **Метрики Оцінки:** Залежно від типу задачі використовуються різні метрики, такі як точність (accuracy), середньоквадратична помилка (MSE) для регресії, F1-міра для класифікації тощо.\n",
    "\n",
    "#### Важливість Розуміння Результатів Моделі\n",
    "- **Інтерпретація Результатів:** Здатність пояснити, чому модель приймає певні рішення, є ключовою для довіри та прийняття рішень.\n",
    "- **Уникнення Перенавчання:** Важливо забезпечити, щоб модель не перенавчилася на тренувальних даних, втрачаючи здатність до узагальнення.\n",
    "\n",
    "---\n",
    "\n",
    "### Приклад Коду: Крос-Валідація та Оцінка Моделі\n",
    "\n",
    "**Мета:** Показати метод крос-валідації для оцінки моделі.\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd\n",
    "\n",
    "# Завантаження та підготовка даних\n",
    "data = pd.read_csv('sample_data.csv')\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "# Створення моделі\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Крос-валідація\n",
    "scores = cross_val_score(model, X, y, cv=5)  # cv вказує на кількість блоків для крос-валідації\n",
    "print(f'Точність на кожному блоку: {scores}')\n",
    "print(f'Середня точність: {scores.mean()}')\n",
    "```\n",
    "\n",
    "У цьому прикладі використовується крос-валідація для оцінки моделі класифікації (Random\n",
    "\n",
    " Forest). Крос-валідація дозволяє оцінити загальну точність моделі, використовуючи різні частини даних як тренувальні та тестові набори. Це допомагає зрозуміти, наскільки добре модель буде працювати на нових, раніше невідомих даних."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Практичні Заняття з Машинного Навчання\n",
    "\n",
    "#### 1. Робота з Реальними Наборами Даних: Iris Dataset\n",
    "**Опис:** Iris dataset — це класичний набір даних у галузі машинного навчання, що містить інформацію про різні види квітів ірису. Дані включають виміри пелюсток та чашолистків.\n",
    "\n",
    "**Завдання:** Класифікація видів ірису на основі їхніх морфологічних ознак.\n",
    "\n",
    "#### 2. Використання Scikit-learn для Розробки Моделей: Класифікація Ірисів\n",
    "**Мета:** Використовуючи Scikit-learn, розробити модель класифікації для ідентифікації видів ірису.\n",
    "\n",
    "**Код:**\n",
    "```python\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Завантаження даних\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Розділення даних на тренувальний та тестовий набори\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)\n",
    "\n",
    "# Створення моделі KNN\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Тренування моделі\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Оцінка моделі\n",
    "y_pred = knn.predict(X_test)\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n",
    "```\n",
    "\n",
    "#### 3. Аналіз та Інтерпретація Результатів\n",
    "**Мета:** Оцінити ефективність моделі та інтерпретувати результати.\n",
    "\n",
    "- **Матриця Помилок (Confusion Matrix):** Дозволяє оцінити, скільки інстанцій було правильно та неправильно класифіковано.\n",
    "- **Звіт про Класифікацію (Classification Report):** Включає такі метрики, як точність, відтворення та F1-міра для кожного класу.\n",
    "\n",
    "**Інтерпретація:**\n",
    "- Високі значення точності та F1-міри вказують на те, що модель добре впоралася з класифікацією видів ірису.\n",
    "- Аналізуючи матрицю помилок, можна виявити, чи є конкретні види, які модель плутає.\n",
    "\n",
    "Цей практичний приклад демонструє процес розробки та оцінки моделі машинного навчання, починаючи від підготовки даних до аналізу результатів. Використання таких простих, але водночас інформативних наборів даних, як Iris, дозволяє студентам зрозуміти ключові концепції машинного навчання."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
